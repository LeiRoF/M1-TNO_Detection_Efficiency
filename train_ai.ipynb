{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_multiplier = 1 # increase the size of the subset by taking random composition of CCD\n",
    "epoch = 60              # number of epochs for each AI\n",
    "n = 1                  # number of loops for the genertic algorithm\n",
    "K = 1                   # number of folds (= number of independant AI per generation)\n",
    "\n",
    "train_prop = 0.7        # proportion of the dataset used for training\n",
    "\n",
    "weights = [7.686424453317564,2.8124992994763316,0.448360122048755,4.727911837705288] # not yet implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import data_io\n",
    "import utils.archive as archive\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas            as pd\n",
    "import tensorflow        as tf\n",
    "from   IPython.display   import display\n",
    "from   tensorflow        import keras\n",
    "from   classes.block     import Block\n",
    "from   classes.triplet   import Triplet\n",
    "from   classes.shot      import Shot\n",
    "from   classes.ccd       import CCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definding the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train):\n",
    "    # mse = tf.keras.losses.MeanSquaredError()\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input((len(x_train[0]),), name=\"InputLayer\"))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n1'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n2'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', name='Dense_n3'))\n",
    "    model.add(keras.layers.Dense(4, name='Output'))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data_io.loadAll() # comment if already loaded to spare time\n",
    "\n",
    "# Formating data in data set usable by the AI\n",
    "data = data_io.get_ai_ready(func=\"tan\",subsets_per_block=subset_multiplier)\n",
    "\n",
    "# Normalization\n",
    "mean = data[:,:-4].mean()\n",
    "std  = data[:,:-4].std()\n",
    "data[:,:-4] = (data[:,:-4] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural nework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "minScore = None\n",
    "path = archive.new(name = archive.description(M = subset_multiplier, N = n, K = K, E = epoch))\n",
    "output = open(f\"{path}/ouput.csv\",\"w\")\n",
    "\n",
    "# Loop over generations (genetic algorithm)\n",
    "for i in range(n):\n",
    "  \n",
    "  print(f\"üîÅ Generation {i+1}/{n}\")\n",
    "\n",
    "  # Shuffling data and creating folds\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  folds = []\n",
    "  for j in range(K):\n",
    "    folds.append(data[j::K])\n",
    "\n",
    "################################################################################\n",
    "  # Splitting data for training and test...\n",
    "\n",
    "  x_train = []; y_train = []; x_test = []; y_test = []\n",
    "  for j, fold in enumerate(folds):\n",
    "    train_sets = int(len(fold)*train_prop)\n",
    "    index = np.zeros(len(fold),dtype=bool)\n",
    "    index[:train_sets] = True\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    data_train = fold[index]\n",
    "    data_test  = fold[~index]\n",
    "\n",
    "    x_train.append(data_train[:,:-4])\n",
    "    y_train.append(data_train[:,-4:])\n",
    "    x_test.append(data_test [:,:-4])\n",
    "    y_test.append(data_test [:,-4:])\n",
    "  \n",
    "  x_train = np.array(x_train); y_train = np.array(y_train); x_test = np.array(x_test); y_test = np.array(y_test)\n",
    "\n",
    "  ################################################################################\n",
    "  # Training K models independently\n",
    "\n",
    "  models = []; history = []; scores = []\n",
    "  for j in range(K):\n",
    "    X = np.concatenate(x_train[np.arange(len(x_train))!=j])\n",
    "    Y = np.concatenate(y_train[np.arange(len(y_train))!=j])\n",
    "\n",
    "    if len(models) < j+1: models.append(get_model(X))\n",
    "    else: models.append(model)\n",
    "\n",
    "    print(f\"üèÉ‚Äç‚ôÄÔ∏è Training model  with fold {j} as test...\", end=\"\\r\")\n",
    "\n",
    "    history.append(models[j].fit(X, Y, epochs = epoch, verbose = 0))#, validation_data = (x_test[j], y_test[j])))\n",
    "\n",
    "    scores.append(models[j].evaluate(x_test[j], y_test[j], verbose=0))\n",
    "\n",
    "  output.write(f\"Generation {i+1}; \")\n",
    "  if minScore is None: minScore = scores[0][0]\n",
    "  if model is None: model = models[0]\n",
    "  for j,s in enumerate(scores):\n",
    "    output.write(f\"{s[0]}; \") \n",
    "    if s[0] < minScore:\n",
    "      minScore = s[0]\n",
    "      model = models[j]\n",
    "  output.write(f\"{minScore}\\n\") \n",
    "\n",
    "  ################################################################################\n",
    "  # Making new prediction\n",
    "\n",
    "  print(\"üîÆ Prediction...\")\n",
    "  \n",
    "  new_data = Block.all[\"2015BD\"].to_ai_ready(func=\"square\")\n",
    "\n",
    "  new_x = new_data[:-4]\n",
    "  new_y = new_data[-4:]\n",
    "  new_x = (new_x - mean) / std\n",
    "\n",
    "  new_x=np.array(new_x).reshape(1,len(new_x))\n",
    "\n",
    "  predictions = model.predict(new_x)\n",
    "  print(f\"Prediction : {predictions[0]}\")\n",
    "\n",
    "  ################################################################################\n",
    "  # Plotting the result\n",
    "\n",
    "  def ft(m,a,b,c,d):\n",
    "      return a/4 * (1-np.tanh((m-b)/c)) * (1-np.tanh((m-b)/d))\n",
    "\n",
    "  def fs(m,a,b,c,d):\n",
    "      return (a-b*(m-21)**2) / (1+np.exp((m-c)/d))\n",
    "\n",
    "  m = np.linspace(21,25.5,1000)\n",
    "  plt.subplot(int(np.ceil(np.sqrt(n))),int(np.ceil(np.sqrt(n))),i+1)\n",
    "  plt.plot(m,ft(m,*predictions[0]), label=\"Machine Learning\")\n",
    "  plt.plot(m,fs(m,new_y[0],new_y[1],new_y[2],new_y[3]), label=\"Excpected\")\n",
    "  if i == 0: plt.title(\"TNO detection rate\")\n",
    "  if i+1>n-np.ceil(np.sqrt(n)):    plt.xlabel(\"Magnitude\")\n",
    "  if i%np.ceil(np.sqrt(n))==0: plt.ylabel(\"Efficiency\")\n",
    "  plt.grid()\n",
    "  if i==0: plt.legend()\n",
    "\n",
    "################################################################################\n",
    "# Saving results\n",
    "\n",
    "output.close()\n",
    "plt.savefig(f\"{path}/tno_efficiency_rate.png\")\n",
    "model.save(f\"{path}/model.ckpt\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0d398e7c3cc3d2b8386dfea47f5eae3378d5d39db7e2c8ef87e93246db0bfd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
